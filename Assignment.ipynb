{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a85d4dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 139 files belonging to 2 classes.\n",
      "Using 112 files for training.\n",
      "Found 139 files belonging to 2 classes.\n",
      "Using 27 files for validation.\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 5s 828ms/step - loss: 0.8629 - accuracy: 0.5179 - val_loss: 0.5936 - val_accuracy: 0.6667\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 5s 800ms/step - loss: 0.6117 - accuracy: 0.6518 - val_loss: 0.7039 - val_accuracy: 0.5556\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 5s 815ms/step - loss: 0.5685 - accuracy: 0.6786 - val_loss: 0.5069 - val_accuracy: 0.7778\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 5s 815ms/step - loss: 0.4759 - accuracy: 0.7857 - val_loss: 0.4765 - val_accuracy: 0.7407\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 5s 807ms/step - loss: 0.3971 - accuracy: 0.8482 - val_loss: 0.5215 - val_accuracy: 0.7407\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 5s 813ms/step - loss: 0.3231 - accuracy: 0.8304 - val_loss: 0.5524 - val_accuracy: 0.7037\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 5s 841ms/step - loss: 0.2278 - accuracy: 0.9286 - val_loss: 0.4250 - val_accuracy: 0.8889\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 5s 814ms/step - loss: 0.1857 - accuracy: 0.9286 - val_loss: 0.6999 - val_accuracy: 0.7037\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 5s 897ms/step - loss: 0.1294 - accuracy: 0.9554 - val_loss: 0.8692 - val_accuracy: 0.7407\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 7s 1s/step - loss: 0.0613 - accuracy: 0.9821 - val_loss: 1.4365 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1605ac880>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import os, os.path\n",
    "\n",
    "\n",
    "data_dir = \"/Users/basangouda/Desktop/CMPE_249/workspace\"\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123)\n",
    "\n",
    "data_dir = \"/Users/basangouda/Desktop/CMPE_249/workspace\"\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123)\n",
    "\n",
    "numclasses = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "      layers.experimental.preprocessing.Rescaling(1./255),\n",
    "      layers.Conv2D(32, 3, activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(32, 3, activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(32, 3, activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dropout(rate=0.5),\n",
    "      layers.Dense(numclasses, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(train_ds, validation_data = val_ds, epochs = 10, batch_size = 32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a6be5fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3519097 , 0.64809024]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "\n",
    "def load(filename):\n",
    "   np_image = Image.open(filename)\n",
    "   np_image = np.array(np_image).astype('float32')/255\n",
    "   np_image = transform.resize(np_image, (256, 256, 3))\n",
    "   np_image = np.expand_dims(np_image, axis=0)\n",
    "   return np_image\n",
    "\n",
    "image = load('/Users/basangouda/Desktop/CMPE_249/workspace_1/test/in mind while driving on highways....jpg')\n",
    "model.predict(image)\n",
    "#predictions = model.predict(image)\n",
    "\n",
    "#predicted_class = np.argmax(predictions, axis=-1)\n",
    "\n",
    "#print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e1b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
